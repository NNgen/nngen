{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Represent a DNN model as a dataflow by NNgen operators\n",
    "--------------------\n",
    "\n",
    "In NNgen, a DNN model is defined by \"define and run\" manner.\n",
    "You can build up a DNN model by chaining NNgen operators.\n",
    "\n",
    "For the supported NNgen operator list, please see \"nngen/operators/\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import nngen as ng\n",
    "\n",
    "\n",
    "# data types\n",
    "act_dtype = ng.int8\n",
    "weight_dtype = ng.int8\n",
    "bias_dtype = ng.int32\n",
    "scale_dtype = ng.int8\n",
    "batchsize = 1\n",
    "\n",
    "# input\n",
    "input_layer = ng.placeholder(dtype=act_dtype,\n",
    "                             shape=(batchsize, 32, 32, 3),  # N, H, W, C\n",
    "                             name='input_layer')\n",
    "\n",
    "# layer 0: conv2d (with bias and scale (= batchnorm)), relu, max_pool\n",
    "w0 = ng.variable(dtype=weight_dtype,\n",
    "                 shape=(64, 3, 3, 3),  # Och, Ky, Kx, Ich\n",
    "                 name='w0')\n",
    "b0 = ng.variable(dtype=bias_dtype,\n",
    "                 shape=(w0.shape[0],), name='b0')\n",
    "s0 = ng.variable(dtype=scale_dtype,\n",
    "                 shape=(w0.shape[0],), name='s0')\n",
    "\n",
    "a0 = ng.conv2d(input_layer, w0,\n",
    "               strides=(1, 1, 1, 1),\n",
    "               bias=b0,\n",
    "               scale=s0,\n",
    "               act_func=ng.relu,\n",
    "               dtype=act_dtype,\n",
    "               sum_dtype=ng.int32)\n",
    "\n",
    "a0p = ng.max_pool_serial(a0,\n",
    "                         ksize=(1, 2, 2, 1),\n",
    "                         strides=(1, 2, 2, 1))\n",
    "\n",
    "# layer 1: conv2d, relu, reshape\n",
    "w1 = ng.variable(weight_dtype,\n",
    "                 shape=(64, 3, 3, a0.shape[-1]),\n",
    "                 name='w1')\n",
    "b1 = ng.variable(bias_dtype,\n",
    "                 shape=(w1.shape[0],),\n",
    "                 name='b1')\n",
    "s1 = ng.variable(scale_dtype,\n",
    "                 shape=(w1.shape[0],),\n",
    "                 name='s1')\n",
    "\n",
    "a1 = ng.conv2d(a0p, w1,\n",
    "               strides=(1, 1, 1, 1),\n",
    "               bias=b1,\n",
    "               scale=s1,\n",
    "               act_func=ng.relu,\n",
    "               dtype=act_dtype,\n",
    "               sum_dtype=ng.int32)\n",
    "\n",
    "a1r = ng.reshape(a1, [batchsize, -1])\n",
    "\n",
    "# layer 2: full-connection, relu\n",
    "w2 = ng.variable(weight_dtype,\n",
    "                 shape=(256, a1r.shape[-1]),\n",
    "                 name='w2')\n",
    "b2 = ng.variable(bias_dtype,\n",
    "                 shape=(w2.shape[0],),\n",
    "                 name='b2')\n",
    "s2 = ng.variable(scale_dtype,\n",
    "                 shape=(w2.shape[0],),\n",
    "                 name='s2')\n",
    "\n",
    "a2 = ng.matmul(a1r, w2,\n",
    "               bias=b2,\n",
    "               scale=s2,\n",
    "               transposed_b=True,\n",
    "               act_func=ng.relu,\n",
    "               dtype=act_dtype,\n",
    "               sum_dtype=ng.int32)\n",
    "\n",
    "# layer 3: full-connection, relu\n",
    "w3 = ng.variable(weight_dtype,\n",
    "                 shape=(10, a2.shape[-1]),\n",
    "                 name='w3')\n",
    "b3 = ng.variable(bias_dtype,\n",
    "                 shape=(w3.shape[0],),\n",
    "                 name='b3')\n",
    "s3 = ng.variable(scale_dtype,\n",
    "                 shape=(w3.shape[0],),\n",
    "                 name='s3')\n",
    "\n",
    "# output\n",
    "output_layer = ng.matmul(a2, w3,\n",
    "                         bias=b3,\n",
    "                         scale=s3,\n",
    "                         transposed_b=True,\n",
    "                         name='output_layer',\n",
    "                         dtype=act_dtype,\n",
    "                         sum_dtype=ng.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Assign quantized weights to the NNgen operators\n",
    "--------------------\n",
    "\n",
    "Constructed NNgen operators contain no weight values. To verify the constructed NNgen dataflow as a software in an integer precision, weight values must be assigned to each ng.variable by \"set_value\" method.\n",
    "\n",
    "In this example, random floating-point values produced by NumPy are assigned. Then the assigned weight values are quantized into integer values. In real cases, actual floating-point weight values obtained by a DNN framework should be assigned and then quantized. Alternatively, you can assign directly integer weight values quantized by yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this example, random floating-point values are assigned.\n",
    "# In a real case, you should assign actual weight values\n",
    "# obtianed by a training on DNN framework.\n",
    "\n",
    "# If you don't you NNgen's quantizer, you can assign integer weights to each tensor.\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "w0_value = np.random.normal(size=w0.length).reshape(w0.shape)\n",
    "w0_value = np.clip(w0_value, -3.0, 3.0)\n",
    "w0.set_value(w0_value)\n",
    "\n",
    "b0_value = np.random.normal(size=b0.length).reshape(b0.shape)\n",
    "b0_value = np.clip(b0_value, -3.0, 3.0)\n",
    "b0.set_value(b0_value)\n",
    "\n",
    "s0_value = np.ones(s0.shape)\n",
    "s0.set_value(s0_value)\n",
    "\n",
    "w1_value = np.random.normal(size=w1.length).reshape(w1.shape)\n",
    "w1_value = np.clip(w1_value, -3.0, 3.0)\n",
    "w1.set_value(w1_value)\n",
    "\n",
    "b1_value = np.random.normal(size=b1.length).reshape(b1.shape)\n",
    "b1_value = np.clip(b1_value, -3.0, 3.0)\n",
    "b1.set_value(b1_value)\n",
    "\n",
    "s1_value = np.ones(s1.shape)\n",
    "s1.set_value(s1_value)\n",
    "\n",
    "w2_value = np.random.normal(size=w2.length).reshape(w2.shape)\n",
    "w2_value = np.clip(w2_value, -3.0, 3.0)\n",
    "w2.set_value(w2_value)\n",
    "\n",
    "b2_value = np.random.normal(size=b2.length).reshape(b2.shape)\n",
    "b2_value = np.clip(b2_value, -3.0, 3.0)\n",
    "b2.set_value(b2_value)\n",
    "\n",
    "s2_value = np.ones(s2.shape)\n",
    "s2.set_value(s2_value)\n",
    "\n",
    "w3_value = np.random.normal(size=w3.length).reshape(w3.shape)\n",
    "w3_value = np.clip(w3_value, -3.0, 3.0)\n",
    "w3.set_value(w3_value)\n",
    "\n",
    "b3_value = np.random.normal(size=b3.length).reshape(b3.shape)\n",
    "b3_value = np.clip(b3_value, -3.0, 3.0)\n",
    "b3.set_value(b3_value)\n",
    "\n",
    "s3_value = np.ones(s3.shape)\n",
    "s3.set_value(s3_value)\n",
    "\n",
    "# Quantizing the floating-point weights by the NNgen quantizer.\n",
    "# Alternatively, you can assign integer weights by yourself to each tensor.\n",
    "\n",
    "imagenet_mean = np.array([0.485, 0.456, 0.406]).astype(np.float32)\n",
    "imagenet_std = np.array([0.229, 0.224, 0.225]).astype(np.float32)\n",
    "\n",
    "if act_dtype.width > 8:\n",
    "    act_scale_factor = 128\n",
    "else:\n",
    "    act_scale_factor = int(round(2 ** (act_dtype.width - 1) * 0.5))\n",
    "\n",
    "input_scale_factors = {'input_layer': act_scale_factor}\n",
    "input_means = {'input_layer': imagenet_mean * act_scale_factor}\n",
    "input_stds = {'input_layer': imagenet_std * act_scale_factor}\n",
    "\n",
    "ng.quantize([output_layer], input_scale_factors, input_means, input_stds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) Assign hardware attributes\n",
    "--------------------\n",
    "\n",
    "The default hardware organization is not properly parallelized. According to a performance requirement and resource constraints, parallelism in various directions can be configured via \"attribute\" method of each operator.\n",
    "\n",
    "NNgen hardware executes a DNN model in integer precision. Thus, right-shift operations are inserted to the tail of (almost) each operator. The amount of right-shift (shamt) also can be assigned via \"attribute\" method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv2d, matmul\n",
    "# par_ich: parallelism in input-channel\n",
    "# par_och: parallelism in output-channel\n",
    "# par_col: parallelism in pixel column\n",
    "# par_row: parallelism in pixel row\n",
    "\n",
    "par_ich = 2\n",
    "par_och = 2\n",
    "\n",
    "a0.attribute(par_ich=par_ich, par_och=par_och)\n",
    "a1.attribute(par_ich=par_ich, par_och=par_och)\n",
    "a2.attribute(par_ich=par_ich, par_och=par_och)\n",
    "output_layer.attribute(par_ich=par_ich, par_och=par_och)\n",
    "\n",
    "# cshamt_out: right shift amount after applying bias/scale\n",
    "# If you assign integer weights by yourself to each tensor,\n",
    "# cshamt (constant shift amount) must be assigned to each operator.\n",
    "\n",
    "# a0.attribute(cshamt_out=weight_dtype.width + 1)\n",
    "# a1.attribute(cshamt_out=weight_dtype.width + 1)\n",
    "# a2.attribute(cshamt_out=weight_dtype.width + 1)\n",
    "# output_layer.attribute(cshamt_out=weight_dtype.width + 1)\n",
    "\n",
    "# max_pool\n",
    "# par: parallelism in in/out channel\n",
    "\n",
    "par = par_och\n",
    "\n",
    "a0p.attribute(par=par)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) Verify the DNN model behavior by executing the NNgen dataflow as a software\n",
    "--------------------\n",
    "\n",
    "After weight values are assigned, the constructed NNgen dataflow can be executed as a software to verify a quantized DNN model. \"ng.eval\" method evaluates the NNgen dataflow according to input values passed via method arguments.\n",
    "\n",
    "In this example, random integer values are produced by NumPy, and are assigned as an input. However, actual integer input values, such as image data opened by PIL, should be assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -1   7   0 -14  -5  -2  -9   7  21  12]]\n"
     ]
    }
   ],
   "source": [
    "# In this example, random integer values are assigned.\n",
    "# In real case, you should assign actual integer activation values, such as an image.\n",
    "\n",
    "input_layer_value = np.random.normal(size=input_layer.length).reshape(input_layer.shape)\n",
    "input_layer_value = input_layer_value * imagenet_std + imagenet_mean\n",
    "input_layer_value = np.clip(input_layer_value, -3.0, 3.0)\n",
    "input_layer_value = input_layer_value * act_scale_factor\n",
    "input_layer_value = np.clip(input_layer_value,\n",
    "                            -1 * 2 ** (act_dtype.width - 1) - 1, 2 ** (act_dtype.width - 1))\n",
    "input_layer_value = np.round(input_layer_value).astype(np.int64)\n",
    "\n",
    "eval_outs = ng.eval([output_layer], input_layer=input_layer_value)\n",
    "output_layer_value = eval_outs[0]\n",
    "\n",
    "print(output_layer_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) Convert the NNgen dataflow to a hardware description (Verilog HDL and IP-XACT)\n",
    "--------------------\n",
    "\n",
    "After all the weights are assigned and the hardware attributes are configured, the NNgen dataflow is ready to be converted to an actual hardware description.\n",
    "\n",
    "You can specify the hardware parameters, such as a data width of the AXI interface and system-wide signal names, via the \"config\" argument. Please see \"nngen/verilog.py\" for all the list of configurable hardware parameters.\n",
    "\n",
    "NNgen generates an all-inclusive dedicated hardware design for an input DNN model, which includes parallel processing elements, on-chip memories, on-chip network between the processing elements and the on-chip memories, a DMA controller between off-chip memories and on-chip memories, and FSM-based control circuits. Therefore, no external control, such as DMA on CPU is required after the generated hardware begins a computation.\n",
    "\n",
    "NNgen supports 3 types of output: 1) Veriloggen object, which is Python-based high-level hardware abstraction, 2) IP-XACT, which is a common IP-core format, and 3) Verilog HDL RTL as a text file.\n",
    "A generated Veriloggen object can be easily verified by a testing mechanism of Veriloggen and a Verilog simulator.\n",
    "A generated IP-XACT IP-core can be integrated with other components via AMBA AXI4 interface on an FPGA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNgen: Neural Network Accelerator Generator (version 1.3.0)\n",
      "[IP-XACT]\n",
      "  Output: hello_nngen\n",
      "[Configuration]\n",
      "(AXI Master Interface)\n",
      "  Data width   : 32\n",
      "  Address width: 32\n",
      "(AXI Slave Interface)\n",
      "  Data width   : 32\n",
      "  Address width: 32\n",
      "[Schedule Table]\n",
      "(Stage 0)\n",
      "(Stage 1)\n",
      "  <conv2d None dtype:int8 shape:(1, 32, 32, 64) strides:(1, 1, 1, 1) padding:'SAME'-(1, 1, 1, 1) bias:(64,) scale:(64,) cshamt_out:10 act_func:relu sum_dtype:int32 par_ich:2 par_och:2 concur_och:16 stationary:filter keep_input default_addr:4242240 g_index:0 l_index:1 word_alignment:4 aligned_shape:(1, 32, 32, 64) scale_factor:2.645833>\n",
      "  | <placeholder input_layer dtype:int8 shape:(1, 32, 32, 3) default_addr:64 g_index:2 word_alignment:4 aligned_shape:(1, 32, 32, 4) scale_factor:64.000000>\n",
      "  | <variable w0 dtype:int8 shape:(64, 3, 3, 3) default_addr:4160 g_index:3 word_alignment:4 aligned_shape:(64, 3, 3, 4) scale_factor:42.333333>\n",
      "  | <variable b0 dtype:int32 shape:(64,) default_addr:4160 g_index:3 word_alignment:2 aligned_shape:(64,) scale_factor:2709.333333>\n",
      "  | <variable s0 dtype:int8 shape:(64,) default_addr:4160 g_index:3 word_alignment:4 aligned_shape:(64,) scale_factor:1.000000>\n",
      "(Stage 2)\n",
      "  <max_pool_serial None dtype:int8 shape:(1, 16, 16, 64) ksize:(1, 2, 2, 1) strides:(1, 2, 2, 1) padding:'SAME'-(0, 0, 0, 0) par:2 no_reuse default_addr:4307776 g_index:0 l_index:2 word_alignment:4 aligned_shape:(1, 16, 16, 64) scale_factor:2.645833>\n",
      "  | <conv2d None dtype:int8 shape:(1, 32, 32, 64) strides:(1, 1, 1, 1) padding:'SAME'-(1, 1, 1, 1) bias:(64,) scale:(64,) cshamt_out:10 act_func:relu sum_dtype:int32 par_ich:2 par_och:2 concur_och:16 stationary:filter keep_input default_addr:4242240 g_index:0 l_index:1 word_alignment:4 aligned_shape:(1, 32, 32, 64) scale_factor:2.645833>\n",
      "(Stage 3)\n",
      "  <conv2d None dtype:int8 shape:(1, 16, 16, 64) strides:(1, 1, 1, 1) padding:'SAME'-(1, 1, 1, 1) bias:(64,) scale:(64,) cshamt_out:10 act_func:relu sum_dtype:int32 par_ich:2 par_och:2 concur_och:16 stationary:filter default_addr:4324160 g_index:0 l_index:3 word_alignment:4 aligned_shape:(1, 16, 16, 64) scale_factor:0.109382>\n",
      "  | <max_pool_serial None dtype:int8 shape:(1, 16, 16, 64) ksize:(1, 2, 2, 1) strides:(1, 2, 2, 1) padding:'SAME'-(0, 0, 0, 0) par:2 no_reuse default_addr:4307776 g_index:0 l_index:2 word_alignment:4 aligned_shape:(1, 16, 16, 64) scale_factor:2.645833>\n",
      "  | <variable w1 dtype:int8 shape:(64, 3, 3, 64) default_addr:4160 g_index:3 word_alignment:4 aligned_shape:(64, 3, 3, 64) scale_factor:42.333333>\n",
      "  | <variable b1 dtype:int32 shape:(64,) default_addr:4160 g_index:3 word_alignment:2 aligned_shape:(64,) scale_factor:112.006944>\n",
      "  | <variable s1 dtype:int8 shape:(64,) default_addr:4160 g_index:3 word_alignment:4 aligned_shape:(64,) scale_factor:1.000000>\n",
      "(Stage 4)\n",
      "  <_lazy_reshape None dtype:int8 shape:(1, 16384) alias_of:<conv2d> default_addr:4324160 g_index:0 l_index:3 word_alignment:4 aligned_shape:(1, 16384) scale_factor:0.109382>\n",
      "  | <conv2d None dtype:int8 shape:(1, 16, 16, 64) strides:(1, 1, 1, 1) padding:'SAME'-(1, 1, 1, 1) bias:(64,) scale:(64,) cshamt_out:10 act_func:relu sum_dtype:int32 par_ich:2 par_och:2 concur_och:16 stationary:filter default_addr:4324160 g_index:0 l_index:3 word_alignment:4 aligned_shape:(1, 16, 16, 64) scale_factor:0.109382>\n",
      "(Stage 5)\n",
      "  <matmul None dtype:int8 shape:(1, 256) bias:(256,) scale:(256,) cshamt_out:12 act_func:relu sum_dtype:int32 par_left_col:2 par_out_col:2 concur_out_col:4 stationary:right keep_left default_addr:4340544 g_index:0 l_index:4 word_alignment:4 aligned_shape:(1, 256) scale_factor:0.001130>\n",
      "  | <_lazy_reshape None dtype:int8 shape:(1, 16384) alias_of:<conv2d> default_addr:4324160 g_index:0 l_index:3 word_alignment:4 aligned_shape:(1, 16384) scale_factor:0.109382>\n",
      "  | <variable w2 dtype:int8 shape:(256, 16384) default_addr:4160 g_index:3 word_alignment:4 aligned_shape:(256, 16384) scale_factor:42.333333>\n",
      "  | <variable b2 dtype:int32 shape:(256,) default_addr:4160 g_index:3 word_alignment:2 aligned_shape:(256,) scale_factor:4.630495>\n",
      "  | <variable s2 dtype:int8 shape:(256,) default_addr:4160 g_index:3 word_alignment:4 aligned_shape:(256,) scale_factor:1.000000>\n",
      "(Stage 6)\n",
      "  <matmul output_layer dtype:int8 shape:(1, 10) bias:(10,) scale:(10,) cshamt_out:8 sum_dtype:int32 par_left_col:2 par_out_col:2 concur_out_col:256 stationary:right keep_left keep_right default_addr:0 g_index:1 word_alignment:4 aligned_shape:(1, 12) scale_factor:0.000187>\n",
      "  | <matmul None dtype:int8 shape:(1, 256) bias:(256,) scale:(256,) cshamt_out:12 act_func:relu sum_dtype:int32 par_left_col:2 par_out_col:2 concur_out_col:4 stationary:right keep_left default_addr:4340544 g_index:0 l_index:4 word_alignment:4 aligned_shape:(1, 256) scale_factor:0.001130>\n",
      "  | <variable w3 dtype:int8 shape:(10, 256) default_addr:4160 g_index:3 word_alignment:4 aligned_shape:(10, 256) scale_factor:42.333333>\n",
      "  | <variable b3 dtype:int32 shape:(10,) default_addr:4160 g_index:3 word_alignment:2 aligned_shape:(10,) scale_factor:0.047857>\n",
      "  | <variable s3 dtype:int8 shape:(10,) default_addr:4160 g_index:3 word_alignment:4 aligned_shape:(12,) scale_factor:1.000000>\n",
      "[RAM (spec: num)]\n",
      "  64-bit 256-entry 2-port 1-bank RAM: 1\n",
      "  16-bit 32768-entry 2-port 2-bank RAM: 2\n",
      "  16-bit 8192-entry 2-port 2-bank RAM: 1\n",
      "  16-bit 512-entry 2-port 2-bank RAM: 31\n",
      "[Substream (spec: num)]\n",
      "  ('acc_rshift_round_frac', (32, 0, True, 32, 0, True)): 2\n",
      "  ('add_tree', (32, 0, True, 2)): 2\n",
      "  ('add_tree', (32, 0, True, 18)): 2\n",
      "  ('mul_rshift_clip', (32, 0, True, 8, 0, True, 40, 0, True, 8, 0, True)): 2\n",
      "  ('mul_rshift_round_madd', (8, 0, True, 8, 0, True, 16, 0, True)): 36\n",
      "  ('reduce_max', (8, 0, True)): 2\n",
      "[Stream (spec: num)]\n",
      "  (((<class 'nngen.operator.conv2d.conv2d'>, <dtype int8>, <dtype int8>, <dtype int32>, <dtype int8>), <dtype int8>, 1), 3, 3, None, <dtype int32>, 2, 2, 1, 1, 9, 36): 1\n",
      "  (((<class 'nngen.operator.pool_serial.max_pool_serial'>, <dtype int8>), <dtype int8>, 2), 2, 2, True, 2): 1\n",
      "  (((<class 'nngen.operator.basic._lazy_reshape'>, <dtype int8>), <dtype int8>, 1), True): 1\n",
      "  (((<class 'nngen.operator.matmul.matmul'>, <dtype int8>, <dtype int8>, <dtype int32>, <dtype int8>), <dtype int8>, 1), 1, 1, None, <dtype int32>, 2, 2, 1, 1, 1, 4): 1\n",
      "[Control (name (# states: num))]\n",
      "  main_fsm (# states: 58)\n",
      "  control_conv2d_4 (# states: 56)\n",
      "  control_max_pool_serial_6 (# states: 26)\n",
      "  control_matmul_16 (# states: 41)\n",
      "[Register Map]\n",
      "   0 (R ): header0 (default: 0)\n",
      "   4 (R ): header1 (default: 0)\n",
      "   8 (R ): header2 (default: 0)\n",
      "  12 (R ): header3 (default: 0)\n",
      "  16 ( W): Start (set '1' to run)\n",
      "  20 (R ): Busy (returns '1' when running)\n",
      "  24 ( W): Reset (set '1' to initialize internal logic)\n",
      "  28 (R ): Opcode from extern objects to SW (returns '0' when idle)\n",
      "  32 ( W): Resume extern objects (set '1' to resume)\n",
      "  36 (RW): Global address offset (default: 0)\n",
      "  40 (RW): Address of temporal storages (size: 97KB)\n",
      "  44 (RW): Address of output (matmul) 'output_layer' (size: 64B, dtype: int8, shape: (1, 10), alignment: 4 words (4 bytes)), aligned shape: (1, 12)\n",
      "  48 (RW): Address of placeholder 'input_layer' (size: 4KB, dtype: int8, shape: (1, 32, 32, 3), alignment: 4 words (4 bytes)), aligned shape: (1, 32, 32, 4)\n",
      "  52 (RW): Address of variables 'w0', 'b0', 's0', 'w1', 'b1', 's1', 'w2', 'b2', 's2', 'w3', 'b3', 's3' (size: 4139KB)\n",
      "[Default Memory Map (start - end)] (entire range: [0 - 4340799], size: 4240KB)\n",
      "  [      0 -      63]: output (matmul) 'output_layer' (size: 64B, dtype: int8, shape: (1, 10), alignment: 4 words (4 bytes)), aligned shape: (1, 12)\n",
      "  [     64 -    4159]: placeholder 'input_layer' (size: 4KB, dtype: int8, shape: (1, 32, 32, 3), alignment: 4 words (4 bytes)), aligned shape: (1, 32, 32, 4)\n",
      "  [   4160 -    6463]: variable 'w0' (size: 3KB, dtype: int8, shape: (64, 3, 3, 3), alignment: 4 words (4 bytes)), aligned shape: (64, 3, 3, 4)\n",
      "  [   6464 -    6719]: variable 'b0' (size: 256B, dtype: int32, shape: (64,), alignment: 2 words (8 bytes)), aligned shape: (64,)\n",
      "  [   6720 -    6783]: variable 's0' (size: 64B, dtype: int8, shape: (64,), alignment: 4 words (4 bytes)), aligned shape: (64,)\n",
      "  [   6784 -   43647]: variable 'w1' (size: 36KB, dtype: int8, shape: (64, 3, 3, 64), alignment: 4 words (4 bytes)), aligned shape: (64, 3, 3, 64)\n",
      "  [  43648 -   43903]: variable 'b1' (size: 256B, dtype: int32, shape: (64,), alignment: 2 words (8 bytes)), aligned shape: (64,)\n",
      "  [  43904 -   43967]: variable 's1' (size: 64B, dtype: int8, shape: (64,), alignment: 4 words (4 bytes)), aligned shape: (64,)\n",
      "  [  43968 - 4238271]: variable 'w2' (size: 4096KB, dtype: int8, shape: (256, 16384), alignment: 4 words (4 bytes)), aligned shape: (256, 16384)\n",
      "  [4238272 - 4239295]: variable 'b2' (size: 1KB, dtype: int32, shape: (256,), alignment: 2 words (8 bytes)), aligned shape: (256,)\n",
      "  [4239296 - 4239551]: variable 's2' (size: 256B, dtype: int8, shape: (256,), alignment: 4 words (4 bytes)), aligned shape: (256,)\n",
      "  [4239552 - 4242111]: variable 'w3' (size: 3KB, dtype: int8, shape: (10, 256), alignment: 4 words (4 bytes)), aligned shape: (10, 256)\n",
      "  [4242112 - 4242175]: variable 'b3' (size: 64B, dtype: int32, shape: (10,), alignment: 2 words (8 bytes)), aligned shape: (10,)\n",
      "  [4242176 - 4242239]: variable 's3' (size: 64B, dtype: int8, shape: (10,), alignment: 4 words (4 bytes)), aligned shape: (12,)\n",
      "  [4242240 - 4340799]: temporal storages (size: 97KB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# IP-XACT was generated. Check the current directory.\n"
     ]
    }
   ],
   "source": [
    "silent = False\n",
    "axi_datawidth = 32\n",
    "\n",
    "# to Veriloggen object\n",
    "# targ = ng.to_veriloggen([output_layer], 'hello_nngen', silent=silent,\n",
    "#                        config={'maxi_datawidth': axi_datawidth})\n",
    "\n",
    "# to IP-XACT (the method returns Veriloggen object, as well as to_veriloggen)\n",
    "targ = ng.to_ipxact([output_layer], 'hello_nngen', silent=silent,\n",
    "                    config={'maxi_datawidth': axi_datawidth})\n",
    "print('# IP-XACT was generated. Check the current directory.')\n",
    "\n",
    "# to Verilog HDL RTL (the method returns a source code text)\n",
    "# rtl = ng.to_verilog([output_layer], 'hello_nngen', silent=silent,\n",
    "#                    config={'maxi_datawidth': axi_datawidth})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(6) Save the quantized weights\n",
    "--------------------\n",
    "\n",
    "All weight parameters are zipped into a single np.ndarray by \"ng.export_ndarray\" method. This array will be utilized in actual FPGA platform later. So please save it using \"np.save\" method as a binary file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert weight values to a memory image:\n",
    "# on a real FPGA platform, this image will be used as a part of the model definition.\n",
    "param_filename = 'hello_nngen.npz'\n",
    "chunk_size = 64\n",
    "\n",
    "param_data = ng.export_ndarray([output_layer], chunk_size)\n",
    "np.savez_compressed(param_filename, param_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(6) Simulate the generated hardware by Veriloggen and Verilog simulator\n",
    "--------------------\n",
    "\n",
    "If you want to reduce the development time, you can skip this section for Verilog simulation.\n",
    "\n",
    "If you generate a hardware as Veriloggen object or IP-XACT, you can simulate the hardware behavior on Verilog simulator via the testing mechanism on Veriloggen.\n",
    "\n",
    "Before the hardware runs, the input data and weight values should be located on the shared off-chip memory. In Verilog simulation in the example, there is a np.ndarray object to represent a dump image of the off-chip memory. You can copy the pre-computed values to the memory image by \"axi.set_memory\" method.\n",
    "\n",
    "\"param_data\" is the unified parameter data of all variables and constants. Locations of the located data are configurable, which can be changed from the CPU via the configuration register of the NNgen hardware. In the following example, the head address of unified parameter data (variblae_addr) is calculated by the same rule as the address calculator in the NNgen compiler.\n",
    "\n",
    "\"ctrl\" method in the following example is an emulation of a control program on the CPU, which is actually an FSM circuit of the control sequence synthesized by the procedural high-level synthesis compiler of Veriloggen. By \"ng.sim.start\" method, the program writes '1' to the \"start\" register of the NNgen hardware. Then the hardware begins the computation, and the CPU waits until the computation finishes by \"ng.sim.wait\" method.\n",
    "\n",
    "### Data alignment, and \"word_alignment\" and \"aligned_shape\"\n",
    "\n",
    "**Note that all the input, weight, and output data should be located along with their alignments.** Especially, using a narrower data width (for any data) than the AXI interconnect interface and applying the parallelization via the hardware attribute will require special cares of data arrangement. In a synthesis log, you can find the **word_alignment** and **aligned_shape** for each placeholder, variable, operator. When putting corresponding data on an off-chip memory, a padding will be required according to the word alignment. The difference between the original shape and the aligned shape is the size of padding. In NNgen, padding is required only at an inner-most dimension.\n",
    "\n",
    "Unified variable images, such as \"param_data\", are already aligned according to the word alignment. So you don't have to rearrange the data alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# start\n",
      "# end\n",
      "# execution cycles:     1906729\n",
      "OK (           0           0 ) orig:           -1  check:           -1\n",
      "OK (           0           1 ) orig:            7  check:            7\n",
      "OK (           0           2 ) orig:            0  check:            0\n",
      "OK (           0           3 ) orig:          -14  check:          -14\n",
      "OK (           0           4 ) orig:           -5  check:           -5\n",
      "OK (           0           5 ) orig:           -2  check:           -2\n",
      "OK (           0           6 ) orig:           -9  check:           -9\n",
      "OK (           0           7 ) orig:            7  check:            7\n",
      "OK (           0           8 ) orig:           21  check:           21\n",
      "OK (           0           9 ) orig:           12  check:           12\n",
      "# verify: PASSED\n",
      "- hello_nngen.out/out.v:1092: Verilog $finish\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# If you don't check the RTL behavior, exit here.\n",
    "# print('# Skipping RTL simulation. If you simulate the RTL behavior, comment out the next line.')\n",
    "# sys.exit()\n",
    "\n",
    "import math\n",
    "from veriloggen import *\n",
    "import veriloggen.thread as vthread\n",
    "import veriloggen.types.axi as axi\n",
    "\n",
    "outputfile = 'hello_nngen.out'\n",
    "filename = 'hello_nngen.v'\n",
    "# simtype = 'iverilog'\n",
    "simtype = 'verilator'\n",
    "\n",
    "param_bytes = len(param_data)\n",
    "\n",
    "variable_addr = int(\n",
    "    math.ceil((input_layer.addr + input_layer.memory_size) / chunk_size)) * chunk_size\n",
    "check_addr = int(math.ceil((variable_addr + param_bytes) / chunk_size)) * chunk_size\n",
    "tmp_addr = int(math.ceil((check_addr + output_layer.memory_size) / chunk_size)) * chunk_size\n",
    "\n",
    "memimg_datawidth = 32\n",
    "mem = np.zeros([1024 * 1024 * 256 // memimg_datawidth], dtype=np.int64)\n",
    "mem = mem + [100]\n",
    "\n",
    "# placeholder\n",
    "axi.set_memory(mem, input_layer_value, memimg_datawidth,\n",
    "               act_dtype.width, input_layer.addr,\n",
    "               max(int(math.ceil(axi_datawidth / act_dtype.width)), par_ich))\n",
    "\n",
    "# parameters (variable and constant)\n",
    "axi.set_memory(mem, param_data, memimg_datawidth,\n",
    "               8, variable_addr)\n",
    "\n",
    "# verification data\n",
    "axi.set_memory(mem, output_layer_value, memimg_datawidth,\n",
    "               act_dtype.width, check_addr,\n",
    "               max(int(math.ceil(axi_datawidth / act_dtype.width)), par_och))\n",
    "\n",
    "# test controller\n",
    "m = Module('test')\n",
    "params = m.copy_params(targ)\n",
    "ports = m.copy_sim_ports(targ)\n",
    "clk = ports['CLK']\n",
    "resetn = ports['RESETN']\n",
    "rst = m.Wire('RST')\n",
    "rst.assign(Not(resetn))\n",
    "\n",
    "# AXI memory model\n",
    "if outputfile is None:\n",
    "    outputfile = os.path.splitext(os.path.basename(__file__))[0] + '.out'\n",
    "\n",
    "memimg_name = 'memimg_' + outputfile\n",
    "\n",
    "memory = axi.AxiMemoryModel(m, 'memory', clk, rst,\n",
    "                            datawidth=axi_datawidth,\n",
    "                            memimg=mem, memimg_name=memimg_name,\n",
    "                            memimg_datawidth=memimg_datawidth)\n",
    "memory.connect(ports, 'maxi')\n",
    "\n",
    "# AXI-Slave controller\n",
    "_saxi = vthread.AXIMLite(m, '_saxi', clk, rst, noio=True)\n",
    "_saxi.connect(ports, 'saxi')\n",
    "\n",
    "# timer\n",
    "time_counter = m.Reg('time_counter', 32, initval=0)\n",
    "seq = Seq(m, 'seq', clk, rst)\n",
    "seq(\n",
    "    time_counter.inc()\n",
    ")\n",
    "\n",
    "\n",
    "def ctrl():\n",
    "    for i in range(100):\n",
    "        pass\n",
    "\n",
    "    ng.sim.set_global_addrs(_saxi, tmp_addr)\n",
    "\n",
    "    start_time = time_counter.value\n",
    "    ng.sim.start(_saxi)\n",
    "\n",
    "    print('# start')\n",
    "\n",
    "    ng.sim.wait(_saxi)\n",
    "    end_time = time_counter.value\n",
    "\n",
    "    print('# end')\n",
    "    print('# execution cycles: %d' % (end_time - start_time))\n",
    "\n",
    "    # verify\n",
    "    ok = True\n",
    "    for bat in range(output_layer.shape[0]):\n",
    "        for x in range(output_layer.shape[1]):\n",
    "            orig = memory.read_word(bat * output_layer.aligned_shape[1] + x,\n",
    "                                    output_layer.addr, act_dtype.width)\n",
    "            check = memory.read_word(bat * output_layer.aligned_shape[1] + x,\n",
    "                                     check_addr, act_dtype.width)\n",
    "\n",
    "            if vthread.verilog.NotEql(orig, check):\n",
    "                print('NG (', bat, x,\n",
    "                      ') orig: ', orig, ' check: ', check)\n",
    "                ok = False\n",
    "            else:\n",
    "                print('OK (', bat, x,\n",
    "                      ') orig: ', orig, ' check: ', check)\n",
    "\n",
    "    if ok:\n",
    "        print('# verify: PASSED')\n",
    "    else:\n",
    "        print('# verify: FAILED')\n",
    "\n",
    "    vthread.finish()\n",
    "\n",
    "\n",
    "th = vthread.Thread(m, 'th_ctrl', clk, rst, ctrl)\n",
    "fsm = th.start()\n",
    "\n",
    "uut = m.Instance(targ, 'uut',\n",
    "                 params=m.connect_params(targ),\n",
    "                 ports=m.connect_ports(targ))\n",
    "\n",
    "# simulation.setup_waveform(m, uut)\n",
    "simulation.setup_clock(m, clk, hperiod=5)\n",
    "init = simulation.setup_reset(m, resetn, m.make_reset(), period=100, polarity='low')\n",
    "\n",
    "init.add(\n",
    "    Delay(10000000),\n",
    "    Systask('finish'),\n",
    ")\n",
    "\n",
    "# output source code\n",
    "if filename is not None:\n",
    "    m.to_verilog(filename)\n",
    "\n",
    "# run simulation\n",
    "sim = simulation.Simulator(m, sim=simtype)\n",
    "rslt = sim.run(outputfile=outputfile)\n",
    "\n",
    "print(rslt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
